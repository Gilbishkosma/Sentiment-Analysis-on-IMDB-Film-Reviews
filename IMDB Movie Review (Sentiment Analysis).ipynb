{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Sentiment Analysis is a popular Natural Language Processing (NLP) task which allows us to extract the overall opinion in a text. In this project, we will be performing Sentiment Analysis on some IMDB movie reviews, to classify the overall review as positive or negative. When dealing with text data, a prevalent issue is how to encode the words as a numeric feature that can be used to compute the output of a classification algorithm. Especially because words don’t naturally lend themselves to a numeric ordering, there have been many approaches on how to featurize a text. In this project, we will use the bag of words model, which uses the count of a word in a text as a feature. We will begin by using logistic regression to perform this task, followed by a decision tree approach, and finally, using a random forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import grid_search\n",
    "from sklearn import tree\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in Data\n",
    "Using the function readFile(filename), we will read the contents of a text file and output the contents of the file as a list containing single words. Using this function, we will read all the files into a Pandas Dataframe, in which each row represents a text file and the columns contain the counts of each word in that specific text file. Note that there should be a column for every possible word that occurs throughout all text files, so all the columns together form the unique vocabulary for the dataset. If a word does not appear in a particular file, let its count be 0. In addition, add a column in this Dataframe with the document label, containing either the value ’positive’ or ’negative’. You may also want to add a column with the file name, so you can later check which reviews were incorrectly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segmentWords(s): \n",
    "    return s.split()\n",
    "\n",
    "def readFile(fileName):\n",
    "    # Function for reading file\n",
    "    # input: filename as string\n",
    "    # output: contents of file as list containing single words\n",
    "    contents = []\n",
    "    f = open(fileName)\n",
    "    for line in f:\n",
    "        contents.append(line)\n",
    "    f.close()\n",
    "    result = segmentWords('\\n'.join(contents))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Dataframe containing the counts of each word in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = []\n",
    "\n",
    "for c in os.listdir(\"data_training/train\"):\n",
    "    directory = \"data_training/train/\" + c\n",
    "    for f in os.listdir(directory):\n",
    "        words = readFile(directory + \"/\" + f)\n",
    "        e = {x:words.count(x) for x in words}\n",
    "        e['__FileID__'] = f\n",
    "        e['__CLASS__'] = 1 if c[:3] == 'pos' else 0\n",
    "        d.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a dataframe from d - make sure to fill all the nan values with zeros.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(d).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 42776)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\u0005</th>\n",
       "      <th>\u0013earth</th>\n",
       "      <th>\u0013goodies</th>\n",
       "      <th>\u0013if</th>\n",
       "      <th>\u0013ripley</th>\n",
       "      <th>\u0013suspend</th>\n",
       "      <th>\u0013they</th>\n",
       "      <th>\u0013white\u0014</th>\n",
       "      <th>\u0014</th>\n",
       "      <th>\u0016</th>\n",
       "      <th>...</th>\n",
       "      <th>zukovsky</th>\n",
       "      <th>zundel</th>\n",
       "      <th>zurg's</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zwick's</th>\n",
       "      <th>zwigoff's</th>\n",
       "      <th>zycie</th>\n",
       "      <th>zycie'</th>\n",
       "      <th>|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42776 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     \u0005  \u0013earth  \u0013goodies  \u0013if  \u0013ripley  \u0013suspend  \u0013they  \u0013white\u0014    \u0014    \u0016  \\\n",
       "0  0.0     0.0       0.0  0.0      0.0       0.0    0.0      0.0  0.0  0.0   \n",
       "1  0.0     0.0       0.0  0.0      0.0       0.0    0.0      0.0  0.0  0.0   \n",
       "2  0.0     0.0       0.0  0.0      0.0       0.0    0.0      0.0  0.0  0.0   \n",
       "3  0.0     0.0       0.0  0.0      0.0       0.0    0.0      0.0  0.0  0.0   \n",
       "4  0.0     0.0       0.0  0.0      0.0       0.0    0.0      0.0  0.0  0.0   \n",
       "\n",
       "  ...   zukovsky  zundel  zurg's  zweibel  zwick  zwick's  zwigoff's  zycie  \\\n",
       "0 ...        0.0     0.0     0.0      0.0    0.0      0.0        0.0    0.0   \n",
       "1 ...        0.0     0.0     0.0      0.0    0.0      0.0        0.0    0.0   \n",
       "2 ...        0.0     0.0     0.0      0.0    0.0      0.0        0.0    0.0   \n",
       "3 ...        0.0     0.0     0.0      0.0    0.0      0.0        0.0    0.0   \n",
       "4 ...        0.0     0.0     0.0      0.0    0.0      0.0        0.0    0.0   \n",
       "\n",
       "   zycie'    |  \n",
       "0     0.0  0.0  \n",
       "1     0.0  0.0  \n",
       "2     0.0  0.0  \n",
       "3     0.0  0.0  \n",
       "4     0.0  0.0  \n",
       "\n",
       "[5 rows x 42776 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\u0005</th>\n",
       "      <th>\u0013earth</th>\n",
       "      <th>\u0013goodies</th>\n",
       "      <th>\u0013if</th>\n",
       "      <th>\u0013ripley</th>\n",
       "      <th>\u0013suspend</th>\n",
       "      <th>\u0013they</th>\n",
       "      <th>\u0013white\u0014</th>\n",
       "      <th>\u0014</th>\n",
       "      <th>\u0016</th>\n",
       "      <th>...</th>\n",
       "      <th>zukovsky</th>\n",
       "      <th>zundel</th>\n",
       "      <th>zurg's</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zwick's</th>\n",
       "      <th>zwigoff's</th>\n",
       "      <th>zycie</th>\n",
       "      <th>zycie'</th>\n",
       "      <th>|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.006429</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.001429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.080127</td>\n",
       "      <td>0.272517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.053452</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.128058</td>\n",
       "      <td>0.065426</td>\n",
       "      <td>0.037783</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.037783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42775 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 \u0005       \u0013earth     \u0013goodies          \u0013if      \u0013ripley  \\\n",
       "count  1400.000000  1400.000000  1400.000000  1400.000000  1400.000000   \n",
       "mean      0.000714     0.000714     0.000714     0.000714     0.000714   \n",
       "std       0.026726     0.026726     0.026726     0.026726     0.026726   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          \u0013suspend        \u0013they      \u0013white\u0014            \u0014            \u0016  \\\n",
       "count  1400.000000  1400.000000  1400.000000  1400.000000  1400.000000   \n",
       "mean      0.000714     0.000714     0.000714     0.003571     0.008571   \n",
       "std       0.026726     0.026726     0.026726     0.080127     0.272517   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     2.000000    10.000000   \n",
       "\n",
       "          ...          zukovsky       zundel       zurg's      zweibel  \\\n",
       "count     ...       1400.000000  1400.000000  1400.000000  1400.000000   \n",
       "mean      ...          0.000714     0.001429     0.000714     0.000714   \n",
       "std       ...          0.026726     0.053452     0.026726     0.026726   \n",
       "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "50%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "75%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "max       ...          1.000000     2.000000     1.000000     1.000000   \n",
       "\n",
       "             zwick      zwick's    zwigoff's        zycie       zycie'  \\\n",
       "count  1400.000000  1400.000000  1400.000000  1400.000000  1400.000000   \n",
       "mean      0.006429     0.002857     0.001429     0.000714     0.000714   \n",
       "std       0.128058     0.065426     0.037783     0.026726     0.026726   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       3.000000     2.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                 |  \n",
       "count  1400.000000  \n",
       "mean      0.001429  \n",
       "std       0.037783  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 42775 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    cv676_22202.txt\n",
      "1     cv155_7845.txt\n",
      "2    cv465_23401.txt\n",
      "3    cv398_17047.txt\n",
      "4    cv206_15893.txt\n",
      "Name: __FileID__, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1395    1\n",
       "1396    1\n",
       "1397    1\n",
       "1398    1\n",
       "1399    1\n",
       "Name: __CLASS__, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.__FileID__.head())\n",
    "df.__CLASS__.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training/Validation Split\n",
    "Because we don’t have access to the labels of the test set, we randomly shuffle the dataset and split the data into a training set and validation set, so we can test our trained model on the validation set. In general, even if you have access to the labels of the test set, it is a good idea to use a validation set to prevent overfitting to the test set. (Hint: Use train_test_split from sklearn.model_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into training and validation set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Sample 80% of your dataframe to be the training data\n",
    "\n",
    "* Let the remaining 20% be the validation data (you can filter out the indicies of the original dataframe that weren't selected for the training data)\n",
    "* Split the dataframe for both training and validation data into x and y dataframes - where y contains the labels and x contains the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = df.drop(['__FileID__', '__CLASS__'], axis=1)\n",
    "labels = df.__CLASS__\n",
    "X_train, X_val, Y_train, Y_val = sklearn.model_selection.train_test_split(features, labels, test_size=0.2, \n",
    "                                                                         random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1120, 42774) (280, 42774) (1120,) (280,)\n"
     ]
    }
   ],
   "source": [
    "# this step was done above before splitting data into training and validation set\n",
    "print(X_train.shape, X_val.shape, Y_train.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "Now we train a basic logistic regression model to classify the sentiment of the reviews. Make sure you do not use the filename as a feature if you previously included it in the Dataframe. Compare the accuracy of this basic model on the training set and the validation set. Are you overfitting? Try changing the parameters of the logistic regression, such as adding a regularization term, to reduce the overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Logistic Regression\n",
    "* Use sklearn's linear_model.LogisticRegression() to create model.\n",
    "* Fit the data and labels with model.\n",
    "* Score model with the same data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.0 \n",
      "Validation acc: 0.839285714286\n"
     ]
    }
   ],
   "source": [
    "logreg = sklearn.linear_model.LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "print(\"Train acc:\", logreg.score(X_train, Y_train), \"\\nValidation acc:\", \n",
    "      logreg.score(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A training accuracy of 1.0 shows our base estimator logistic regression model is overfitting the training data. We will need to change the parameters of the model to improve/avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1000, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cs = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "# gamma parameter which inversely controls the standard deviation of our kernel's distribution\n",
    "penalty = ['l1', 'l2']\n",
    "# initialize the dictionary of parameters\n",
    "param_grid = {'C': Cs, 'penalty' : penalty}\n",
    "# initialize the search using input as nfold cross validation\n",
    "lr = sklearn.linear_model.LogisticRegression()\n",
    "search = grid_search.GridSearchCV(lr, param_grid)\n",
    "# fit the search object to our input training data\n",
    "search.fit(X_train, Y_train)\n",
    "# output the best parameters\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc: 1.0 \n",
      "Validation acc: 0.885714285714\n"
     ]
    }
   ],
   "source": [
    "logreg2 = sklearn.linear_model.LogisticRegression(penalty='l1', C=1000)\n",
    "logreg2.fit(X_train, Y_train)\n",
    "print(\"Training acc:\", logreg2.score(X_train, Y_train), \"\\nValidation acc:\", \n",
    "      logreg2.score(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our regularized log reg model still overfits the training data, but it also increased the testing accuracy from 84% to 88.5%, which is most important by a significant amount. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward Stepwise Selection to Reduce Features\n",
    "Overfitting mainly occurs if the model is too expressive for the given task. As a result, it is able to not only fit the pattern in the training data, but also the randomness of the dataset, which thereby causes a high accuracy on the training data and a low accuracy on the test data. One way to reduce the expressiveness of the model is by reducing the number of features. Currently, we used the count of every word present as a feature, but perhaps some words are more indicative of the sentiment of the review than others. Those other words, which don’t contribute much to determining the sentiment, may be overfitting to the noise in the training set. One way to identify these features is to look at the features whose weights are close to 0 (remember to normalize the weights if using this method). This process is called Backward Stepwise Selection, which aims to remove the features whose removal would reduce the test error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection/Reduction\n",
    "* In the backward stepsize selection method, you can remove coefficients and the corresponding x columns, where the coefficient is more than a particular amount away from the mean - you can choose how far from the mean is reasonable.\n",
    "\n",
    "* We selected features here using a recursive feature elimination model that reduces overfitting by shrinking the hypothesis space of our logistic regression model. This didn't give results that were significantly better at reducing overfitting than the L1  regularization above as the testin accuracy increased from 88.5% to a 89.2%, which, when dealing with data at scale, is an increase worth running the backward steps selection (or feature reduction) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A recursive feature elimination approach\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# A new logistic regression model with parameters from above and a feature selector\n",
    "lr2 = sklearn.linear_model.LogisticRegression(C=1000, penalty='l1')\n",
    "selector = RFE(lr2, step=10000, n_features_to_select=41000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit RFE selector to training set\n",
    "selector.fit(X_train, Y_train)\n",
    "lr2 = selector.estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# figure out which columns to drop\n",
    "columns = features.columns\n",
    "feature_mask = selector.support_\n",
    "columns_to_drop = [columns[i] for i in range(columns.size) if not feature_mask[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create print function to print scores of estimators\n",
    "def print_results(estimator, X, y, leadingString=''):\n",
    "    print(leadingString, estimator.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:  1.0\n",
      "Testing results:  0.892857142857\n"
     ]
    }
   ],
   "source": [
    "# show training and testing accuracies after feature reduction\n",
    "print_results(lr2, X_train.drop(columns_to_drop, axis=1), Y_train, \"Training results: \")\n",
    "print_results(lr2, X_val.drop(columns_to_drop, axis=1), Y_val, \"Testing results: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We selected features here using a recursive feature elimination model that reduces overfitting by shrinking the hypothesis space of our logistic regression model. This didn't give results that were significantly better at reducing overfitting than the L1  regularization above as the testing accuracy increased from 88.5% to 89.2%, which, when dealing with data at scale, is an increase that may be worth permitting the computation time and cost of running a Backward Stepwise Selection (or feature reduction) method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Decision Tree\n",
    "\n",
    "* Initialize model as a decision tree with sklearn.\n",
    "* Fit the data and labels to the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc: 1.0 \n",
      "Validation acc: 0.635714285714\n"
     ]
    }
   ],
   "source": [
    "dt_clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "dt_clf.fit(X_train, Y_train)\n",
    "print(\"Training acc:\", dt_clf.score(X_train, Y_train), \"\\nValidation acc:\", dt_clf.score(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is a single decision tree so prone to overfitting?\n",
    "\n",
    "A single decision tree is prone to overfitting because it is able to go out of it's way to search for maximum purity in the nodes, this is not desired as this will easily fit to the noise in the training set and incorrectly estimate the underlying data generating distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Parameters\n",
    "* To test out which value is optimal for a particular parameter, you can either loop through various values or look into `sklearn.model_selection.GridSearchCV`\n",
    "* Side note: next time we should graph the differences in testing and training accuracies between each combination of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'min_samples_split': [5, 10, 50, 100, 500, 1000], 'min_samples_leaf': [10, 100, 1000, 10000], 'max_depth': [None, 10, 100, 1000, 10000], 'max_leaf_nodes': [None, 10, 100, 1000, 10000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\"max_depth\": [None, 10, 100, 1000, 10000],\n",
    "              \"min_samples_split\": [5, 10, 50, 100, 500, 1000],\n",
    "              \"min_samples_leaf\": [10, 100, 1000, 10000],\n",
    "              \"max_leaf_nodes\": [None, 10, 100, 1000, 10000],\n",
    "              }\n",
    "gridsearch = GridSearchCV(dt_clf, parameters)\n",
    "gridsearch.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'max_leaf_nodes': 10000,\n",
       " 'min_samples_leaf': 10,\n",
       " 'min_samples_split': 100}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the best parameters of the gridsearchCV regularized decision tree\n",
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc: 0.757142857143 \n",
      "Validation acc: 0.621428571429\n"
     ]
    }
   ],
   "source": [
    "# use parameters from gridsearchCV above in new decision tree model\n",
    "reg_tree = gridsearch.best_estimator_\n",
    "\n",
    "print(\"Training acc:\", reg_tree.score(X_train, Y_train), \"\\nValidation acc:\",\n",
    "      reg_tree.score(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose these parameters by grid search on orders of magnitude for the different parameters which revealed the order of magnitude of our correct parmeters, from there we performed a manual search for fine tuning. The manual fine-tuned parameters and the corresponding test and training accuracies are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.858035714286\n",
      "Testing score:  0.692857142857\n"
     ]
    }
   ],
   "source": [
    "# create decision tree model with manually searched parameters (best in class)\n",
    "reg_tree2 = tree.DecisionTreeClassifier(criterion = \"entropy\", max_depth = None, max_leaf_nodes = 125, min_samples_leaf = 2, min_samples_split = 60)\n",
    "reg_tree2.fit(X_train, Y_train)\n",
    "\n",
    "# print model training and test accuracies\n",
    "print_results(reg_tree2, X_train, Y_train, \"Training score: \")\n",
    "print_results(reg_tree2, X_val, Y_val, \"Testing score: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, our decision tree model with parameters derived by a manual search produced better testing and training \n",
    "accuracies than both our base decision tree estimator (which severely overfit the training data) and our decision tree model with gridsearch cross validation produced parameters. Still, our best decision tree model above (with manually searched parameters) is significantly lower than our gridsearchCV regularized logistic regression model above (89% test accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add a Boost to your Decision Tree Classifer using AdaBoost( )**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train an AdaBoost classifier using the tuned decision tree model above as the base estimator. Boosting trains weak learners sequentially so they focus on the points that are hard to classify, so make sure to limit each individual tree so it is individually weak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=125,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=60,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=100, random_state=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train an AdaBoost classifier using the tuned random forest model above as the base estimator\n",
    "boost_clf = AdaBoostClassifier(base_estimator=reg_tree2, n_estimators=100)\n",
    "boost_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc: 1.0 \n",
      "Validation acc: 0.739285714286\n"
     ]
    }
   ],
   "source": [
    "print(\"Training acc:\", boost_clf.score(X_train, Y_train), \"\\nValidation acc:\",\n",
    "      boost_clf.score(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The (AdaBoost) boosted decision tree classifier produces the best testing accuracy in (the decision tree) class at 73%. The model may seem to be overfitting the training data, but it captures the general signal or trend of the test data well enough to predict better than the decision tree base estimator and the gridsearchCV tuned decision tree model. Still, logistic regression, a simpler model, seems to be the better, more accurate option for sentiment analysis with this particular IMDB movie review text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Random Forest\n",
    "\n",
    "* Use sklearn's ensemble.RandomForestClassifier() to create your model.\n",
    "* Fit the data and labels with your model.\n",
    "* Score your model with the same data and labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Random Forest classifier prevents overfitting better than a decision tree by using a series of weaker trees that cannot themselves overfit the training set and takes a majority vote from them to classify. Training an AdaBoost Classifier on the same dataset trains weak learners sequentially, so they focus on the points that are hard to classify, so we made sure to limit each individual tree so it is individually weak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc: 1.0 \n",
      "Validation acc: 0.821428571429\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(criterion = 'entropy', n_estimators=100)\n",
    "rfc.fit(X_train, Y_train)\n",
    "print(\"Training acc:\", rfc.score(X_train, Y_train), \"\\nValidation acc:\",\n",
    "      rfc.score(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters = {\"min_samples_split\": [2, 5, 10],\n",
    "              \"max_depth\": [None, 2, 5, 10],\n",
    "              \"min_samples_leaf\": [1, 5, 10],\n",
    "              \"max_leaf_nodes\": [None, 5, 10, 20],\n",
    "              }\n",
    "gridsearch2 = GridSearchCV(rfc, parameters)\n",
    "gridsearch2.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_leaf_nodes': None, 'min_samples_leaf': 10, 'min_samples_split': 100}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc: 0.935714285714 \n",
      "Validation acc: 0.817857142857\n"
     ]
    }
   ],
   "source": [
    "reg_forest = gridsearch2.best_estimator_\n",
    "reg_forest.fit(X_train, Y_train)\n",
    "print(\"Training acc:\", reg_forest.score(X_train, Y_train), \"\\nValidation acc:\",\n",
    "      reg_forest.score(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning the parameters of our random forest classifier using sklearn's GridSearchCV method, we decreased the model's overfitting of the training set from a 100% accuracy to a 93% accuracy. However, our test set accuracy on the parameter-tuned model was slightly lower at 81.7%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add a Boost to Random Forest model with sklearn's AdaBoostClassifier( )**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc: 1.0 \n",
      "Validation acc: 0.882142857143\n"
     ]
    }
   ],
   "source": [
    "boost_reg2 = AdaBoostClassifier(base_estimator=reg_forest)\n",
    "boost_reg2.fit(X_train, Y_train)\n",
    "print(\"Training acc:\", boost_reg2.score(X_train, Y_train), \"\\nValidation acc:\",\n",
    "      boost_reg2.score(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What parameters did you choose to change and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We regularized the model parameters by running a standard grid search on the hyperparameters and received the following hyperparameters: min_samples_split=2, max_depth=None, min_samples_leaf=1, and max_leaf_nodes=None. The resulting model brought the training accuracy down to .90 and the validation set accuracy up to .83. \n",
    "\n",
    "Finally, we trained an AdaBoostClassifier model using our regularized random forest as our base_estimator and received a training accuracy of 1.0 and a testing accuracy of .89. Although the model seems to overfit the training data, it also produces our highest testing accuracy yet. We decided to optimize this AdaBoostClassifier model by running a standard grid search on the n_estimators hyperparameter, which informed us that the best resulting model used a value of 50 for n_estimators. When we ran the resulting AdaBoostClassifier model using our regularized random forest as our base estimator and 50 as our number of estimators, we received a 1.0 training accuracy and a testing accuracy of .88, a class best. Again, the AdaBoost classifiers seem to overfit the training data, most likely due to our base estimator (the regularized random forest) being relatively strong estimators rather than the required weak estimators, but our resulting testing accuracy was a class best at .88. Thus, it seems as though a boosted random forest model does not perform better than the simpler, parameter-tuned logistic regression model, which produced a testing accuracy of 89.2%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does a random forest classifier prevent overfitting better than a single decision tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A Random Forest classifier prevents overfitting better than a decision tree by using a series of weaker trees that cannot themselves overfit the training set and takes a majority vote from them to classify. Training an AdaBoost Classifier on the same dataset trains weak learners sequentially, so they focus on the points that are hard to classify, so we made sure to limit each individual tree so it is individually weak."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
